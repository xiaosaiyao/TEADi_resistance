#!/usr/bin/env Rscript

# Function that implements the dropletUtils R package workflow for demultiplexing HTOs and scRNA data types.
# Briefly, will read HTO matrix generated by the cumulus cell ranger workflow. reads scRNA gex matrix from the arcseq workflow.
# Will then run the DropletUtils workflow: barcodeRanks(), emptyDrops() followed by hashedDrops().
#
# Example:
# demultiplex_hto_and_scRNA.R \
#    -b FRS17654 \
#    -a FRS14086 \
#    -n NGS4467 \
#    -t 0 \
#    -r 30000 \
#    -p 1 \
#    -i 100000 \
#    -d TRUE \
#    -o /gstore/project/tead/multinome/NGS4467_test/output/
#
# Roche/Genentech
# Author: Julien Tremblay - julien.tremblay@contractors.roche.com

demultiplex_hto_and_scRNA <- function(num_threads=1, ngs_id=NULL, outdir=NULL, test_ranks=NULL, rank=20000, hto_frs_id=NULL, arcseq_frs_id=NULL, n_iters=50000, skip_sample=NULL, debug_hashedDrops=FALSE,
                                      doublets_nmads=3, doublets_min=2, confidents_nmads=1, confidents_min=1){
    
    #########################################
    # parameters. Manually set for debug.   #
    # comment for real run                  @
    #########################################
    #num_threads = 4
    #ngs_id = "NGS4467"
    #hto_frs_id = "FRS17654"
    #arcseq_frs_id = "FRS14086"
    #outdir = "/gstore/project/tead/scMultiome/NGS4467_pilot_JT/"
    #test_ranks = NULL
    #rank = 30000
    #n_iters = 100000
    #skip_sample = NULL
    #debug_hashedDrops = FALSE
    
    message("Running demultiplex_hto_and_scRNA with following parameters")
    message("num_threads :", num_threads)
    message("ngs_id :", ngs_id)
    message("outdir :", outdir)
    message("test_ranks :", test_ranks)
    message("rank :", rank)
    message("hto_frs_id :", hto_frs_id)
    message("arcseq_frs_id :", arcseq_frs_id)
    message("n_iters :", n_iters)
    message("skip_sample :", skip_sample)
    message("debug_hashedDrops :", debug_hashedDrops)
    
    num_threads = as.numeric(num_threads)
    rank = as.numeric(rank)
    n_iters = as.numeric(n_iters)
    debug_hashedDrops = as.logical(debug_hashedDrops)
   
    # Debuging input parameters.
    skip_test_ranks = FALSE
    if(!is.null(test_ranks)){
        if(length(test_ranks) == 1){
            if(test_ranks == 0){
                message("Will skip the testing of multiple ranks.")
                skip_test_ranks = TRUE
            }
        }
    }else{
        skip_test_ranks = TRUE
    }
    message("skip_test_ranks: ", skip_test_ranks)

    if(!is.null(rank)){
        if(rank == 0){
            stop("rank has to be more than 0")
        }
    }else{
        stop("rank=<int> has to be included")
    }
    
    if(!is.null(n_iters)){
        if(n_iters == 0){
            stop("n_iters has to be more than 0")
        }
    }else{
        stop("n_iters=<int> has to be included")
    }

    if(!is.null(rank)){
        if(rank == 0){
            stop("rank has to be more than 0")
        }
    }
    
    if(is.null(hto_frs_id)){
        stop("a hto_frs_id value has to be included")
    }
    
    if(is.null(arcseq_frs_id)){
        stop("a arcseq_frs_id value has to be included")
    }
    
    library(zellkonverter)
    library(scater)
    library(ArchR)
    library(gridExtra)
    library(DropletUtils)
    library(ggplot2)
    library(SingleCellExperiment)
    library(Matrix)
    library(scater)
    library(BiocParallel)
    library(data.table)
    library(dplyr)
    library(ggpubr)
    library(scales)

    #######################
    # parameters          #
    #######################
    bpparam = BiocParallel::MulticoreParam(workers = num_threads) # not used because intermitenly crashes.
    setwd(outdir)

    # Get HTO data
    # Get file paths through maw.utils
    hto_info = maw.utils::getFireDBResourceSetInfo(frs.id = hto_frs_id)$file
    # when generating HTO files only, the file path will actually point to a directory on the amazon cloud. 
    # process the output to retrieve the path on rosalind
    hto_info$uri = gsub("output\\/LIB\\d+_SAM\\d+", "", hto_info$uri)
    hto_info$uri = gsub("s3:\\/\\/gred-cumulus-data\\/sunrise", "\\/gstore\\/data\\/genomics\\/congee_rest_runs", hto_info$uri)
    hto_path = unique(paste0(hto_info$uri, ngs_id, "/croo_output/"))
    # get files from directory on rosalind
    hto_files = list.files(hto_path, pattern="*.hashing.csv", recursive=TRUE, full.names=TRUE)
    # skip SAM24417356 (pool3 LIB5457059_SAM24417356)
    hto_info2 = data.frame(hto_files)
    hto_info2$sample = gsub(".*_(SAM\\d+).*", "\\1", hto_info2$hto_files)

    # Get arcseq matrices
    # Skip SAM24417356 (pool3 LIB5457059_SAM24417356)
    arcseq_info = maw.utils::getFireDBResourceSetInfo(frs.id = arcseq_frs_id)$file
    arcseq_files = list.files(paste0(arcseq_info$uri, "/"), pattern="*raw_feature_bc_matrix", recursive=TRUE, full.names=TRUE)
    if(!is.null(skip_sample)){
        arcseq_files = arcseq_files[!grepl("SAM24417356", arcseq_files)]
    }
    arcseq_info2 = data.frame(arcseq_files)
    arcseq_info2$sample = gsub(".*(SAM\\d+).*", "\\1", arcseq_info2$arcseq_files)

    # Now we have all our files in hands.
    # Get a vector of samples and loop through each sample to process files.
    samples = gsub(".*_(SAM\\d+).*", "\\1", hto_files)

    # Here, each loop will process one SAM ID
    summary_df_final = NULL
    seRNA_objects = list()
    tables = list()
    empty_drops = list()
    hashed_drops = list()
    for(i in 1:length(samples)){
        summary_df = NULL
      
        curr_sample = samples[i]
        message("Processing ", curr_sample)
        dir.create(paste0(outdir, "/", curr_sample, "/figures"), recursive=TRUE)
        dir.create(paste0(outdir, "/", curr_sample, "/tables"), recursive=TRUE)
        dir.create(paste0(outdir, "/", curr_sample, "/rds"), recursive=TRUE)
      
        curr_arcseq_file = arcseq_info2[arcseq_info2$sample == curr_sample,]$arcseq_files
        curr_hto_file    = hto_info2[hto_info2$sample == curr_sample,]$hto_files
      
        ###########################
        # import gex              #
        ###########################
        message("...Importing arcseq matrix")
        seRNA <- ArchR::import10xFeatureMatrix(
            input = file.path(curr_arcseq_file),
            names = curr_sample
        )
        names(assays(seRNA)) = "counts"
        # coerce seRNA obs to a SingleCellExperiment because it is a RangedSingleCellExperiment at this point.
        seRNA = as(seRNA, "SingleCellExperiment")
        # Here if you look at the seRNA obj, there are approx 725k single-cells: at this point, they are NOT single cells, but droplets and the
        # vast majority of them are empty (processed below)
      
        ###########################################
        # import HTO and convert to sce object.   #
        ###########################################
        message("...Importing HTO matrix")
        hto = data.frame(fread(curr_hto_file, header=T), check.names=FALSE)
        rownames_hto = hto$Antibody
        hto = hto[,-1]
        # Here remember that each hto also contains a cell barcode sequence. in the next line,
        # we are formatting each cell barcode the way as it is formatted in the seRNA object
        # will be used later to only keep cell barcodes for which we have an assigned hto.
        colnames(hto) = paste0(curr_sample, "#", colnames(hto), "-1")
        hto = as(as.matrix(hto), "dgCMatrix")
        rownames(hto) = rownames_hto
        hto = SingleCellExperiment(assays = list(counts=hto))
      
        # merge GEX and HTO into a SCE
        # Only keep seRNA cells that are found in hto data.
        common_cells = intersect(colnames(hto), colnames(seRNA))
        message("Number of droplets: ", length(colnames(seRNA)),
              "\nNumber of HTOs: ", length(colnames(hto)),
              "\nNumber of droplets common to both datasets: ", length(common_cells))
        summary_df = data.frame(Description=c("Number_of_droplets", "Number_of_HTOs", "Number_of_droplets_common_to_HTO_and_scRNA"),
                              sample_name_placeholder=c(length(colnames(seRNA)), length(colnames(hto)), length(common_cells)))
        colnames(summary_df)[2] = curr_sample
        # Then, narrow selection to common cells.
        hto = hto[, common_cells] # row=features, col=cells
        # Same selection with seRNA obj (remember both SingleCellExperiment and SummarizedExperiment classes have the same structure)
        seRNA = seRNA[, common_cells]
        # coerce seRNA obs to a SingleCellExperiment because it is a RangedSingleCellExperiment at this point.
        seRNA = as(seRNA, "SingleCellExperiment")
        # Add HTO data as altExp attribute, see doc for more details.
        altExp(seRNA, "HTO") = hto
      
        ###################################################
        # Distinguish single cells from empty droplets.   #
        ###################################################
        # Remove all zeros
        # Aatually, we can't remove rows at this point, only col (i.e. single cells) at this point. because downstream, we'll have to merge various objects. We'll have to do that later downstream.
        seRNA = seRNA[, Matrix::colSums(assays(seRNA)$counts) > 0]
        summary_df = rbind(summary_df, c("Non-empty_droplets_(count>0)", ncol(seRNA)))#data.frame(Description = nrow(seRNA)))
        # Have a look at barcode ranks:
        empty_thresh = 100 # remove more invalid cells.
        bc_ranks = barcodeRanks(counts(seRNA), lower=empty_thresh)
      
        # Add colData to seRNA obj (i.e. bc_ranks hold barcodes in the same order as it was in the seRNA obj)
        colData(seRNA)$BarcodeRank   = bc_ranks$rank
        colData(seRNA)$BarcodeTotal  = bc_ranks$total
        colData(seRNA)$BarcodeFitted = bc_ranks$fitted
      
        bc_data = colData(seRNA) %>%
            as.data.frame() %>%
            select(Rank=BarcodeRank, Total=BarcodeTotal, Fitted=BarcodeFitted) %>%
            arrange(Rank)
      
        p_barcode_ranks = ggplot(bc_data, aes(x = Rank, y = Total)) +
            geom_point(shape = 1) + #, aes(colour = Kept)) +
            scale_x_log10(labels = scales::number) +
            scale_y_log10(labels = scales::number) +
            geom_hline(yintercept = empty_thresh,
                   colour = "darkorchid", linetype = "dashed") +
            geom_hline(yintercept = metadata(bc_ranks)$knee,
                  colour = "dodgerblue", linetype = "dashed") +
            annotate("text", x = 0, y = metadata(bc_ranks)$knee, label = "Knee",
                 colour = "dodgerblue", hjust = 0, vjust = -1) +
            geom_hline(yintercept = metadata(bc_ranks)$inflection,
                   colour = "forestgreen", linetype = "dashed") +
            annotate("text", x = 0, y = metadata(bc_ranks)$inflection, label = "Inflection",
                 colour = "forestgreen", hjust = 0, vjust = -1) +
            geom_hline(yintercept = empty_thresh,
                   colour = "darkorchid", linetype = "dashed") +
            annotate("text", x = 0, y = empty_thresh, label = "Empty threshold",
                 colour = "darkorchid", hjust = 0, vjust = -1) +
            scale_colour_manual(values = c("black", "violet")) +
            ylab("Total counts") + ggtitle("Total count of each sc barcode in function of their rank (gex data)") +
            theme_minimal() + theme(plot.title = element_text(size = 7))
        pdf(file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_total_counts_by_rank_", curr_sample, ".pdf"), height=5, width=5.5)
        print(p_barcode_ranks)
        dev.off()
      
        # Also check barcode distribution
        hto_df = t(data.frame(fread(curr_hto_file, header=T), check.names=FALSE))
        colnames(hto_df) = hto_df[1,]
        hto_df = hto_df[-1,]
        hto_df = data.frame(hto_df)
        hto_df$cell_barcode = row.names(hto_df)
        hto_df2 = melt(hto_df, id.vars=c("cell_barcode"))
        hto_df2$value = as.numeric(hto_df2$value)
        hto_df2 = hto_df2[hto_df2$value >= 1,]
      
        p_hist1_raw = ggplot(hto_df2, aes(x=value)) + scale_y_log10() +
            facet_wrap(. ~ variable, nrow=4, ncol=4) + 
            geom_histogram(bins=100, fill="#393939") + 
            ylab("log10(count)") + scale_x_continuous(labels=comma) +
            theme_minimal() + theme(axis.text.x=element_text(size=8, hjust=1, angle=90))
      
        pdf(file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_hist_raw_", curr_sample, ".pdf"), height=3, width=8)
        print(p_hist1_raw)
        dev.off()
      
        p_hist1_log10 = ggplot(hto_df2, aes(x=log10(value + 1))) + scale_y_log10() + 
            facet_wrap(. ~ variable, nrow=4, ncol=4) + 
            geom_histogram(bins=100,  fill="#393939") + 
            ylab("log10(count)") + ggtitle("HTO distribution (count >= 1)") +#scale_x_continuous(labels=fancy_scientific) +
            theme_minimal() + theme(plot.title = element_text(size = 7))
      
        pdf( file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_hist_log10_", curr_sample, ".pdf"), height=5, width=5)
        print(p_hist1_log10)
        dev.off()
      
        # From barcodes distribution plot, sharp drop off between droplets with lots of counts and those without many. 
        # Distinguish between droplets containing cells and ambient RNA in a droplet-based single-cell RNA sequencing experiment.
        # Use EmptyDrops() method. This method tests whether the composition of a droplet is significantly different from the ambient RNA in the sample 
        # which is obtained by pooling the empty droplets. Droplets with very large counts are also automatically retained
        # call empty droplets to define ambient droplets. From DropletUtils
        # The method by.rank will automatically set the lower=<int> threshold.
        # Here test various by.rank parameters
        # We could add multithreads, but sometimes crashes... so use SerialParam() for now.
        if(skip_test_ranks == FALSE){
            df_ranks = NULL
            for(j in 1:length(test_ranks)){
                print(paste0("j: ", j))
                curr_rank = test_ranks[j]
                emp_drops = emptyDrops(counts(seRNA), lower=NULL, niters=10000,
                                    test.ambient=TRUE, BPPARAM=SerialParam(), by.rank=curr_rank)
                emp_fdr = 0.01
                is_cell = emp_drops$FDR <= emp_fdr
                is_cell[is.na(is_cell)] = FALSE # NA means its not a cell, so force NAs to FALSE
                table(Limited = emp_drops$Limited, Significant=is_cell)
            
                significant_cells = row.names(emp_drops[is_cell==TRUE,])
                non_significant_cells = row.names(emp_drops[is_cell==FALSE,])
                bc_data_filt = bc_data[row.names(bc_data) %in% significant_cells,]
                message("by.rank: ",curr_rank, " signigicant_cells: ", length(significant_cells))
                print(paste0("by.rank: ",curr_rank, " signigicant_cells: ", length(significant_cells)))
            
                if(j == 1){
                    df_ranks = data.frame(rank=curr_rank, no_significant_cells=length(significant_cells), lower=metadata(emp_drops)$lower)
                }else{
                    df_ranks = rbind(df_ranks, data.frame(rank = curr_rank, no_significant_cells=length(significant_cells), lower=metadata(emp_drops)$lower))
                }
            }
          
            p_emptyDrops_ranks = ggplot(bc_data, aes(x = Rank, y = Total)) +
                geom_point(shape = 1) +
                scale_x_log10(labels = scales::number) +
                scale_y_log10(labels = scales::number) +
                scale_y_continuous(trans = "log10") + 
                geom_hline(yintercept = empty_thresh,
                       colour = "darkorchid", linetype = "dashed") +
                geom_hline(yintercept = metadata(bc_ranks)$knee,
                       colour = "dodgerblue", linetype = "dashed") +
                annotate("text", x = 0, y = metadata(bc_ranks)$knee, label = "Knee",
                       colour = "dodgerblue", hjust = 0, vjust = -1, size=3) +
                geom_hline(yintercept = metadata(bc_ranks)$inflection,
                       colour = "forestgreen", linetype = "dashed") +
                annotate("text", x = 0, y = metadata(bc_ranks)$inflection, label = "Inflection",
                     colour = "forestgreen", hjust = 0, vjust = -1, size=3) +
                geom_hline(yintercept = empty_thresh,
                       colour = "darkorchid", linetype = "dashed") +
                annotate("text", x = 0, y = empty_thresh, label = "Empty threshold",
                     colour = "darkorchid", hjust = 0, vjust = -1, size=3) +
                scale_colour_manual(values = c("black", "violet"))

            counter = 1
            last_y_pos = NULL
            for(j in 1:length(test_ranks)){
                p_emptyDrops_ranks = p_emptyDrops_ranks + 
                    geom_hline(yintercept = df_ranks[j,]$lower, linewidth=0.2,
                       colour = "red", linetype = "dashed") +
              
                    annotate("text", 
                      x = (max(bc_data$Rank)*0.20), 
                      y = df_ranks[j,]$lower,
                      label = paste0(df_ranks[j,]$lower, "<by_rank=", df_ranks[j,]$rank, ">"),
                      colour = "red", hjust = 0, vjust = -1, size=2.5
                    )
            }
            p_emptyDrops_ranks = p_emptyDrops_ranks + ggtitle("Total count of each sc barcode in function of their rank (gex data)\nwith various emptyDrops() cutoffs") + 
                ylab("Total counts") +
                theme_minimal() + theme(plot.title = element_text(size = 7))
            pdf(file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_emptyDrops_ranks_", curr_sample, ".pdf"), height=6, width=7)
            print(p_emptyDrops_ranks)
            dev.off()
            png(file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_emptyDrops_ranks_", curr_sample, ".png"), height=6, width=7, units="in", res=300)
            print(p_emptyDrops_ranks)
            dev.off()
        }else{
            p_emptyDrops_ranks = ggplot() + # Draw ggplot2 plot with text only
                annotate("text",
                x = 1,
                 y = 1,
                size = 8,
                label = "Ranks evaluation was skipped.") + 
                theme_void()
        } 
      
        # Barcodes that contain more than retain total counts are always retained. This ensures that large cells with profiles that 
        # are very similar to the ambient pool are not inadvertently discarded. If retain is not specified, it is set to the total 
        # count at the knee point detected by barcodeRanks. Manual specification of retain may be useful if the knee point was not correctly 
        # identified in complex log-rank curves. Users can also set retain=Inf to disable automatic retention of barcodes with large totals.
      
        # All barcodes with total counts above retain are assigned p-values of zero during correction, reflecting our assumption that they are 
        # true positives. This ensures that their Monte Carlo p-values do not affect the correction of other genes, and also means that they will 
        # have FDR values of zero. However, their original Monte Carlo p-values are still reported in the output, as these may be useful for diagnostic purposes.
      
        # So basically, by.rank=20000 looks good, lets go with that value for now.
        # and increase niters to 100000
        curr_rank = rank
        emp_drops = emptyDrops(counts(seRNA), lower=NULL, niters=n_iters,
                             test.ambient = TRUE, BPPARAM=SerialParam(), by.rank=curr_rank)
        emp_fdr = 0.01
        is_cell = emp_drops$FDR <= emp_fdr
        cells_above_fdr = emp_drops$FDR > emp_fdr
        is_cell[is.na(is_cell)] = FALSE # NA means its not a cell, so force NAs to FALSE
        cells_above_fdr[is.na(cells_above_fdr)] = TRUE
        non_significant_cells = row.names(emp_drops[cells_above_fdr,])
        t1 = table(Limited = emp_drops$Limited, Significant = is_cell)
        tables[[curr_sample]] = t1
        empty_drops[[curr_sample]] = emp_drops
      
        significant_cells = row.names(emp_drops[is_cell,]) # row.names returns only rows that have TRUE, when selecting with boolean vector.
        bc_data_filt = bc_data[row.names(bc_data) %in% significant_cells,]
        message("by.rank: ",curr_rank, " signigicant_cells: ", length(significant_cells))
      
        # Double check that results given by emptyDrops match.
        bc_data_filt_less_than_lower = bc_data[bc_data$Total < metadata(emp_drops)$lower,]
        bc_data_filt_in_between = bc_data[bc_data$Total >= metadata(emp_drops)$lower,]
        bc_data_filt_in_between = bc_data_filt_in_between[row.names(bc_data_filt_in_between) %in% non_significant_cells, ]
      
        summary_df = rbind(summary_df, c("Significant_cells_and_higher_than_lower_abundance_threshold", length(significant_cells)))
        summary_df = rbind(summary_df, c("Non_significant_cells_but_higher_than_lower_abundance_threshold", nrow(bc_data_filt_in_between)))
        summary_df = rbind(summary_df, c("Non_significant_cells_and_higher_than_lower_abundance_threshold", nrow(bc_data_filt_less_than_lower)))

        # plot empty droplet assignments 
        emp_drops$r = rank(-emp_drops$Total) # determine the rank of each emp_drops$Total values (in reverse rank order)
      
        p_emp_drops = ggplot(data.frame(emp_drops), aes(x=r, y=Total)) +
            geom_point(shape=1) +
            scale_x_log10(labels = scales::number) +
            scale_y_log10(labels = scales::number) +
            geom_hline(yintercept = metadata(bc_ranks)$knee,
                 colour = "dodgerblue", linetype = "dashed") +
            annotate("text", x = 0, y = metadata(bc_ranks)$knee, label = "Knee",
               colour = "dodgerblue", hjust = 0, vjust = -1) +
            geom_hline(yintercept = metadata(bc_ranks)$inflection,
                 colour = "forestgreen", linetype = "dashed") +
            annotate("text", x = 0, y = metadata(bc_ranks)$inflection, label = "Inflection",
               colour = "forestgreen", hjust = 0, vjust = -1) +
            geom_hline(yintercept = metadata(emp_drops)$retain,
                 colour = "darkorchid", linetype = "dashed") +
            annotate("text", x = 0, y = metadata(emp_drops)$retain, label = "Retain",
               colour = "darkorchid", hjust = 0, vjust = -1) +
            geom_hline(yintercept = metadata(emp_drops)$lower,
                   colour = "orange", linetype = "dashed") +
            annotate("text", x = 0, y = metadata(emp_drops)$lower, label = "Lower",
                 colour = "orange", hjust = 0, vjust = -1) +
            scale_colour_manual(values = c("black", "violet")) +
            ylab("Total counts") + ggtitle(paste0("Total count of each sc barcode in function of their rank\nafter emptyDrops(by.rank=", curr_rank, ")")) +
            theme_minimal() + theme(plot.title = element_text(size = 7))
      
        emp_drops_valid_cells = data.frame(emp_drops[is_cell,])
        emp_drops_valid_cells$status = "valid"
        emp_drops_invalid_cells = data.frame(emp_drops[!is_cell,])
        emp_drops_invalid_cells$status = "invalid"
        emp_drops_valid_and_invalid_cells = rbind(emp_drops_valid_cells, emp_drops_invalid_cells)
      
        # but just to confirm with the whole data...
        emp_drops_significant_cells = bc_data[row.names(bc_data) %in% significant_cells,]
        emp_drops_significant_cells$status = "significant"
        emp_drops_in_between = bc_data[row.names(bc_data) %in%  row.names(bc_data_filt_in_between),]
        emp_drops_in_between$status = "non_significant_but_abundant"
        emp_drops_nonsignificant_cells = bc_data[!row.names(bc_data) %in% c(row.names(emp_drops_significant_cells), row.names(emp_drops_in_between)),]
        emp_drops_nonsignificant_cells$status = "non_significant"
        emp_drops_status = rbind(emp_drops_significant_cells, emp_drops_in_between, emp_drops_nonsignificant_cells)
      
        p_valid_invalid_3 = ggplot(emp_drops_status, aes(x = log10(Total+1), fill=status)) + scale_y_log10(expand=c(0, NA)) +
            geom_histogram(bins=200, position="identity", alpha=0.6) + 
            theme_minimal() + theme(plot.title = element_text(size = 7), legend.text=element_text(size=6), legend.title=element_text(size=0), legend.key.size=unit(0.3, "cm")) +
            ggtitle("Distribution of sc barcode abundance (log10)") +
            xlab("Total counts") +
            ylab("Count (or frequency)")
      
        # Estimate HTO ambient proportions using empty droplets
        hto_mat = assay(altExp(seRNA),"counts")[, which(is_cell)]
        # confirm that by ambient, we mean non-cells... or just really low abundant stuff.
        # Ok, from the documentation, I believe ambient = non-cells HTOs.
        # Get % of each HTO
        ambient_hto_mat = assay(altExp(seRNA), "counts")[,!is_cell]
        ambient_hto_prop = proportions(rowSums(assay(altExp(seRNA), "counts")[,!is_cell]))
        message("Number of ambient HTOs: ", ncol(ambient_hto_mat),", Number of non-ambient (cells) HTOs:", ncol(hto_mat))
      
        # plot ambient proportions
        ambient_hto_prop_df = data.frame(ambient_hto_prop)
        colnames(ambient_hto_prop_df)[1] = "prop"
        ambient_hto_prop_df$HTO = row.names(ambient_hto_prop_df)
        p_ambient_hto_prop = ggplot(ambient_hto_prop_df, aes(x=HTO, y=prop)) +
            geom_bar(stat="identity") + 
            theme_minimal() + theme(plot.title = element_text(size = 7), legend.text=element_text(size=6)) +
            ggtitle("ambient HTO proportion") +
            xlab("HTO ID") +
            ylab("%")
     
        if(debug_hashedDrops == TRUE){
            dir.create(paste0(outdir, "/", curr_sample, "/debug/tables"), recursive=TRUE)
            dir.create(paste0(outdir, "/", curr_sample, "/debug/figures"), recursive=TRUE)
            doublets_nmads = c(1, 1.5, 2, 2.5, 3)
            doublets_min = c(1, 1.5, 2)
            confidents_nmads = c(1, 1.5, 2, 2.5, 3)
            confidents_min = c(1, 1.5, 2)
        }else{
            message(doublets_nmads, doublets_min, confidents_nmads, confidents_min)
        }
        
        ps_debug = list()
        hash_stats_list = list()
        hash_stats_debug_df = NULL
        hash_stats_debug_per_HTO_df = NULL
        k = 1
        for(m in 1:length(doublets_nmads)){
            for(n in 1:length(doublets_min)){
                for(x in 1:length(confidents_nmads)){
                    for(z in 1:length(confidents_min)){
                        curr_config = paste0("dnmads:",doublets_nmads[m],"_dmin:", doublets_min[n], "_cnmads:", confidents_nmads[x], "_cmin:",confidents_min[z])
                        message(k, " - processing: ", curr_config)
                        seRNA_filt = seRNA[, which(is_cell)]

                        hash_stats = hashedDrops(hto_mat, ambient=ambient_hto_prop, 
                                               doublet.nmads=doublets_nmads[m],
                                               doublet.min=doublets_min[n],
                                               confident.nmads=confidents_nmads[x],
                                               confident.min=confidents_min[z]
                        )
                        table(hash_stats$Best[hash_stats$Confident])
                        hashed_drops[[curr_sample]] = hash_stats

                        hash_stats_df = data.frame(hash_stats)
                        hash_stats_df$status = "Probably not a valid HTO"
                        hash_stats_df[hash_stats_df$Doublet == TRUE,]$status = "Doublet"
                        hash_stats_df[hash_stats_df$Confident == TRUE,]$status = "Confident"
                        cell_counts = data.frame(colSums(assays(seRNA_filt)$counts)); colnames(cell_counts)[1] = "counts";
                        hash_stats_df = merge(hash_stats_df, cell_counts, by.x="row.names", by.y="row.names")
                        hash_stats_list[[curr_config]] = hash_stats_df
                        
                        p_hash_stats1 = ggplot(hash_stats_df, aes(x=LogFC, y=LogFC2, color=status)) +
                            geom_point(alpha=0.9, size=0.99) + 
                            xlab("logFC") +
                            ylab("logFC2") +
                            theme_minimal()  + theme(plot.title = element_text(size = 7), legend.text=element_text(size=6), legend.key.size=unit(0.45, "cm"), legend.title=element_blank()) +
                            guides(color = guide_legend(override.aes = list(size=4))) + guides(fill = guide_legend(override.aes = list(size=4))) +  
                            ggtitle("hashedDrops() results")
                        ps_debug[[curr_config]][["hash_stats1"]] = p_hash_stats1
                        
                        p_hash_stats2 = ggplot(hash_stats_df, aes(x=LogFC, y=LogFC2, color=status, size=(sqrt(counts)/25))) +
                            geom_point(alpha=0.5) + 
                            xlab("logFC") +
                            ylab("logFC2") +
                            theme_minimal()  + theme(plot.title = element_text(size = 7), legend.text=element_text(size=6), legend.key.size=unit(0.95, "cm")) +
                            guides(color = guide_legend(override.aes = list(size=4))) + guides(fill = guide_legend(override.aes = list(size=4))) +  
                            ggtitle("hashedDrops() results")
                        ps_debug[[curr_config]][["hash_stats2"]] = p_hash_stats2
                        
                        p_hash_stats3 = ggplot(hash_stats_df, aes(x=status, y=counts, fill=status)) + scale_y_log10() +
                            facet_wrap(. ~ Best) +
                            geom_violin() + geom_boxplot(width=0.1) +
                            ylab("Counts") +
                            theme_minimal()  + theme(axis.text.x = element_blank(), panel.border = element_rect(linewidth=0.05, fill=NA), panel.background=element_blank(), plot.title=element_text(size=7), legend.text=element_text(size=6), legend.key.size=unit(0.4, "cm"), legend.title=element_blank()) +
                            guides(color = guide_legend(override.aes = list(size=2))) + guides(fill = guide_legend(override.aes = list(size=2))) +  
                            ggtitle("hashedDrops() results. y-axis: Number of reads per single-cell (per HTO)")
                        ps_debug[[curr_config]][["hash_stats3"]] = p_hash_stats3
                        
                        #keep only non-empty cells
                        colData(seRNA_filt) = cbind(colData(seRNA_filt), hash_stats)
                        colData(seRNA_filt)$library = sapply(strsplit(colnames(seRNA_filt), split = "#"), "[",1)
                      
                        assay(altExp(seRNA_filt), "logcounts") = log10(assay(altExp(seRNA_filt), "counts")+1)
                        # Then, for each row the logcount is subtracted from mean log count, which basically is a clr.
                        assay(altExp(seRNA_filt), "clr") = sweep(
                                                            assay(altExp(seRNA_filt), "logcounts"), 
                                                            2,
                                                            colMeans(assay(altExp(seRNA_filt), "logcounts")),
                                                            "-"
                                                          )
                        seRNA_filt = runUMAP(seRNA_filt, altexp = "HTO", name="UMAP_HTO", exprs_values = "clr")
                        seRNA_filt$hash_assignment = rownames_hto[seRNA_filt$Best]
                        p_umap_hto_filt = plotReducedDim(seRNA_filt[, which(seRNA_filt$Doublet == FALSE & seRNA_filt$Confident == TRUE)],
                                                                             dimred = "UMAP_HTO",
                                                                             color_by = "hash_assignment",
                                                                             point_size=0.5 ) + ggtitle(curr_sample) +
                                                                             guides(fill = guide_legend(title=NULL, override.aes = list(size=4))) +
                                                                             guides(color = guide_legend(title=NULL, override.aes = list(size=4)))
                        ps_debug[[curr_config]][["umap_hto_filt"]] = p_umap_hto_filt
                      
                        p_umap_hto_all = plotReducedDim(seRNA_filt,
                                                       dimred = "UMAP_HTO",
                                                       color_by = "hash_assignment",
                                                       point_size=0.5 ) + ggtitle(curr_sample) +
                                                       guides(fill = guide_legend(title=NULL, override.aes = list(size=4))) +
                                                       guides(color = guide_legend(title=NULL, override.aes = list(size=4)))
                        ps_debug[[curr_config]][["umap_hto_all"]] = p_umap_hto_all
                      
                        #p_umap_hto_all
                        if(debug_hashedDrops == FALSE){
                             curr_outdir = paste0(outdir, "/", curr_sample)
                        }else{
                             curr_outdir = paste0(outdir, "/", curr_sample, "/debug")
                        }
                        
                        # build stats for important results.
                        significant_cell_barcodes_indices = which(seRNA_filt$Doublet == FALSE & seRNA_filt$Confident == TRUE)
                        tmp_df = data.frame(
                            total_number_of_raw_counts                    = sum(colSums(assays(seRNA_filt)$counts)),
                            total_number_of_raw_counts_assigned_to_an_HTO = sum(rowSums(assays(altExps(seRNA_filt)$HTO)$counts)),
                            number_of_cells_with_HTO_raw                  = dim(colData(seRNA_filt))[1],
                            number_of_doublets                            = nrow(hash_stats_df[hash_stats$Doublet == TRUE,]),
                            number_of_confidents                          = nrow(hash_stats_df[hash_stats$Confident == TRUE,]),
                            number_of_non_confidents_non_doublets         = nrow(hash_stats_df[hash_stats$Confident == FALSE & hash_stats$Doublet == FALSE, ]),
                            number_of_cells_with_significant_HTO          = length(significant_cell_barcodes_indices),
                            doublet_nmads                                 = doublets_nmads[m],
                            doublet_min                                   = doublets_min[n],
                            confident_nmads                               = confidents_nmads[x],
                            confident_min                                 = confidents_min[z],
                            hashedDrops_config                            = curr_config
                        )
                            
                        # Since hto data will not always be in the same order, we have to force it with a merge.
                        tmp_df_per_hto = data.frame(row.names(data.frame(rowSums(assays(altExps(seRNA_filt)$HTO)$counts))))
                        row.names(tmp_df_per_hto) = tmp_df_per_hto[,1]
                        tmp_df_per_hto[,1] = NULL
                            
                        number_of_HTOs_raw_freq = data.frame(table(seRNA_filt$hash_assignment)); row.names(number_of_HTOs_raw_freq) = number_of_HTOs_raw_freq$Var1; number_of_HTOs_raw_freq$Var1 = NULL; colnames(number_of_HTOs_raw_freq)[1] = "number_of_HTOs_raw_freq";
                        number_of_counts_per_HTO_raw = data.frame(rowSums(assays(altExps(seRNA_filt)$HTO)$counts)); colnames(number_of_counts_per_HTO_raw)[1] = "number_of_counts_per_HTO_raw"
                        significant_cell_barcodes_indices = which(seRNA_filt$Doublet == FALSE & seRNA_filt$Confident == TRUE)
                        number_of_HTOs_filt_freq = data.frame(table(seRNA_filt[,significant_cell_barcodes_indices]$hash_assignment)); row.names(number_of_HTOs_filt_freq) = number_of_HTOs_filt_freq$Var1; number_of_HTOs_filt_freq$Var1 = NULL; colnames(number_of_HTOs_filt_freq)[1] = "number_of_HTOs_filt_freq";  # means that we have a total of 16,005 ( sum(table(seRNA_filt$hash_assignment)) ) cells and that we had 322 cells assigned to HTO-9
                        number_of_counts_per_HTO_filt = data.frame(rowSums(assays(altExps(seRNA_filt)$HTO)$counts[,significant_cell_barcodes_indices])); colnames(number_of_counts_per_HTO_filt)[1] = "number_of_counts_per_HTO_filt"
                        #doublets
                        doublet_cell_barcodes_indices = which(seRNA_filt$Doublet == TRUE)
                        number_of_doublet_counts_per_HTO_filt = data.frame(rowSums(assays(altExps(seRNA_filt)$HTO)$counts[,doublet_cell_barcodes_indices])); colnames(number_of_doublet_counts_per_HTO_filt)[1] = "number_of_doublet_counts_per_HTO_filt"
                        number_of_HTOs_doublets_freq = data.frame(table(seRNA_filt[,doublet_cell_barcodes_indices]$hash_assignment)); row.names(number_of_HTOs_doublets_freq) = number_of_HTOs_doublets_freq$Var1; number_of_HTOs_doublets_freq$Var1 = NULL; colnames(number_of_HTOs_doublets_freq)[1] = "number_of_HTOs_doublets_freq";  # means that we have a total of 16,005 ( sum(table(seRNA_filt$hash_assignment)) ) cells and that we had 322 cells assigned to HTO-9
                            
                        tmp_df_per_hto = merge(tmp_df_per_hto, number_of_HTOs_raw_freq, by="row.names", all=TRUE)
                        tmp_df_per_hto = merge(tmp_df_per_hto, number_of_counts_per_HTO_raw, by.x="Row.names", by.y="row.names", all=TRUE)
                        tmp_df_per_hto = merge(tmp_df_per_hto, number_of_HTOs_filt_freq, by.x="Row.names", by.y="row.names", all=TRUE)
                        tmp_df_per_hto = merge(tmp_df_per_hto, number_of_counts_per_HTO_filt, by.x="Row.names", by.y="row.names", all=TRUE)
                        tmp_df_per_hto = merge(tmp_df_per_hto, number_of_doublet_counts_per_HTO_filt, by.x="Row.names", by.y="row.names", all=TRUE)
                        tmp_df_per_hto = merge(tmp_df_per_hto, number_of_HTOs_doublets_freq, by.x="Row.names", by.y="row.names", all=TRUE)
                        row.names(tmp_df_per_hto) = tmp_df_per_hto$Row.names; tmp_df_per_hto$Row.names = NULL;
                        tmp_df_per_hto[is.na(tmp_df_per_hto)] <- 0
                        tmp_df_per_hto = rbind(tmp_df_per_hto, colSums(tmp_df_per_hto))
                        row.names(tmp_df_per_hto)[nrow(tmp_df_per_hto)] = "Total"
                        tmp_df_per_hto$HTO_ID = row.names(tmp_df_per_hto)
                        tmp_df_per_hto = tmp_df_per_hto[,c(7,1,2,3,4,5,6)]
                        row.names(tmp_df_per_hto)[1:nrow(tmp_df_per_hto)] = seq(1,nrow(tmp_df_per_hto),1)
                        tmp_df_per_hto$doublet_nmads                      = doublets_nmads[m]
                        tmp_df_per_hto$doublet_min                        = doublets_min[n]
                        tmp_df_per_hto$confident_nmads                    = confidents_nmads[x]
                        tmp_df_per_hto$confident_min                      = confidents_min[z]
                        tmp_df_per_hto$config = curr_config
                        
                        tmp_df_per_hto2 = t(tmp_df_per_hto[,c(1,2,3,4,5,6,7)]); colnames(tmp_df_per_hto2) = tmp_df_per_hto2[1,]; tmp_df_per_hto2 = tmp_df_per_hto2[-1,]
                        tmp_colnames = colnames(tmp_df_per_hto2)[order(nchar(colnames(tmp_df_per_hto2)), colnames(tmp_df_per_hto2))]
                        tmp_colnames = tmp_colnames[grep("Total", tmp_colnames, invert=T)]
                        tmp_colnames = c(tmp_colnames, "Total")
                        tmp_df_per_hto2 = tmp_df_per_hto2[,tmp_colnames]
                        for(v in 1:ncol(tmp_df_per_hto2)){
                            tmp_df_per_hto2[,v] = as.character(scales::label_comma()(as.numeric(tmp_df_per_hto2[,v])))
                        }
                        tmp_df_per_hto2 = tmp_df_per_hto2[c(1,3,6,2,4,5),]
                        p_table1 = ggtexttable(tmp_df_per_hto2, rows=row.names(tmp_df_per_hto2), theme=ttheme(tbody.style=tbody_style(hjust=1, x=0.9, size=7), base_size = 7))
                        p_table1 = p_table1 %>%
                            tab_add_title(text = curr_config, face = "plain", size = 10)
                        ps_debug[[curr_config]][["table1"]] = p_table1
                        
                        if(k == 1){
                            hash_stats_debug_df = tmp_df
                            hash_stats_debug_per_HTO_df = tmp_df_per_hto
                        }else{
                            hash_stats_debug_df = rbind(hash_stats_debug_df, tmp_df)
                            hash_stats_debug_per_HTO_df = rbind(hash_stats_debug_per_HTO_df, tmp_df_per_hto)
                        }
                        
                        k = k + 1
                    }
                }
            }
        }
        
        # then write plots.        
        figure2_list = list()
        for(x in 1:length(ps_debug)){
            curr_config = names(ps_debug)[x]
            p1 = ps_debug[[curr_config]][["hash_stats1"]]
            p2 = p_emp_drops
            p3 = ps_debug[[curr_config]][["hash_stats3"]]
            p4 = ps_debug[[curr_config]][["umap_hto_all"]]
            p5 = ps_debug[[curr_config]][["umap_hto_filt"]]
            p6 = ps_debug[[curr_config]][["table1"]]
            figure2a = ggarrange(
                p1, p2, p3, p4, p5,
                labels = c("A", "B", "C", "D", "E"),
                ncol = 2, nrow = 3,
                common.legend = FALSE, legend = "bottom",
                font.label = list(size = 10, color = "black", face = "bold", family = NULL, position = "top"))
            
            figure2b = ggarrange(
                p6, labels=c("F"), ncol=1, nrow=1, common.legend=FALSE, legend="bottom", widths=c(1,3),
                font.label = list(size = 10, color = "black", face = "bold", family = NULL, position = "top"))
             
            figure2 = ggarrange(figure2a, figure2b, nrow=2, ncol=1, heights=c(2.5,1))     
            f2 = annotate_figure(figure2, 
                               fig.lab = paste0("\n    ", curr_sample, " - hashedDrops config:", curr_config), 
                               fig.lab.pos = "top.left",
                               top = textGrob("\n", gp = gpar(cex = 0.9), hjust=1.8)
            )
            figure2_list[[curr_config]] = f2
           
            curr_outdir = ""
            if(debug_hashedDrops == TRUE){
                curr_outdir = paste0(outdir, "/", curr_sample, "/debug/figures")
            }else{
                curr_outdir = paste0(outdir, "/", curr_sample, "/figures")
                write.table(tmp_df_per_hto2, paste0(outdir, "/", curr_sample, "/tables/TABLE_summary_hashedDrops_by_HTO_", curr_sample, ".tsv"), sep="\t", quote=FALSE, row.names=FALSE)
            }
            pdf( file=paste0(curr_outdir, "/FIGURE_summary_hashedDrops_debug_", curr_sample, "_", curr_config, ".pdf"), height=12, width=11)
            print(f2)
            dev.off()
            png( file=paste0(curr_outdir, "/FIGURE_summary_hashedDrops_debug_", curr_sample, "_", curr_config, ".png"), height=12, width=11, units="in", res=300)
            print(f2)
            dev.off()
        }
        # END OF hashedDrops debug
        # Then continue main workflow (regardless of hashDrops debug)
            
        # Write combined tables.
        write.table(hash_stats_debug_df, paste0(outdir, "/", curr_sample, "/tables/TABLE_summary_hashedDrops_debug_", curr_sample, ".tsv"), sep="\t", quote=FALSE, row.names=FALSE)
        write.table(hash_stats_debug_per_HTO_df, paste0(outdir, "/", curr_sample, "/tables/TABLE_summary_hashedDrops_debug_per_HTO_", curr_sample, ".tsv"), sep="\t", quote=FALSE, row.names=FALSE)
        
        # save output
        saveRDS(seRNA_filt, paste0(outdir, "/", curr_sample, "/rds/", curr_sample, "_demultiplex_hto_and_scRNA.rds"))
        
        # save tables and summary_df_final objects/tables
        sink(paste0(outdir, "/", curr_sample, "/tables/", curr_sample, "_emptyDropsResults.txt"))
        print(tables[[curr_sample]])
        sink()
        
        write.table(empty_drops[[curr_sample]], file=paste0(outdir, "/", curr_sample, "/tables/emptyDropsTable_", curr_sample, ".tsv"), sep="\t", quote=F)
        write.table(hashed_drops[[curr_sample]], file=paste0(outdir, "/", curr_sample, "/tables/hashDropsTable_", curr_sample, ".tsv"), sep="\t", quote=F)
        
        write.table(summary_df, paste0(outdir, "/", curr_sample, "/tables/summary_", ngs_id, "_", "_", curr_sample, "_", rank, ".tsv"), sep="\t", quote=FALSE, row.names=FALSE)
        
        # and final summary df for combined results.
        if(i == 1){
            summary_df_final = summary_df
        }else{
            summary_df_final = cbind(summary_df_final, summary_df[[ curr_sample ]])
            colnames(summary_df_final)[i+1] = curr_sample
        }
    }
    # End of per sample loop
    
    ###########################
    # Combine plots           #
    ###########################
    if(debug_hashedDrops == FALSE){ # if we did not do debug, write the summary figure.
        figure1 = ggarrange(
            p_hist1_log10, p_emptyDrops_ranks, p_emp_drops, p_valid_invalid_3, p_hash_stats1, p_umap_hto_all, p_umap_hto_filt,
            labels = c("A", "B", "C", "D", "E", "F", "G"),
            ncol = 3, nrow = 3,
            common.legend = FALSE, legend = "bottom",
            align = "hv", 
            font.label = list(size = 10, color = "black", face = "bold", family = NULL, position = "top"))
          
        f1 = annotate_figure(figure1, 
                            fig.lab = paste0("\n    ", curr_sample), 
                            fig.lab.pos = "top.left",
                            top = textGrob("\n", gp = gpar(cex = 0.9), hjust=1.8)
        )
        pdf( file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_summary_", curr_sample, ".pdf"), height=13, width=13)
        print(f1)
        dev.off()
        png( file=paste0(outdir, "/", curr_sample, "/figures/FIGURE_summary_", curr_sample, ".png"), height=13, width=13, units="in", res=300)
        print(f1)
        dev.off()
    }
    

    write.table(summary_df_final, paste0(outdir, "/summary_", ngs_id, "_", rank, ".tsv"), sep="\t", quote=FALSE, row.names=FALSE)

    sink(paste0(outdir, "/", curr_sample, "/sessionInfo.txt"))
    print(sessionInfo())
    sink()

    message("demultiplex_hto_and_scrna.R done...")
}

is.defined <- function(sym) {
    sym <- deparse(substitute(sym))
    env <- parent.frame()
    exists(sym, env)
}

usage=function(errM) {
    cat("\nUsage : Rscript demultiplex_hto_and_scRNA.R [option] <Value>\n")
    cat("       -b        : HTO FRS ID (output of cumulus_cellranger workflow for demultiplexing only.\n")
    cat("       -a        : HTO ARCSEQ ID (output of arcseq workflow.\n")
    cat("       -n        : NGS ID (i.e. NGS[0-9]{4}\n")
    cat("       -t        : list of ranks to test for emptyDroplets(). ints separated by a comma. Ex: 500,1000,20000 . include 0 to skip.\n")
    cat("       -r        : Rank to chose to actually run emptyDroplets(). Int. \n")
    cat("       -p        : num_threads\n")
    cat("       -i        : number of iterations for computing emptyDrops()\n")
    cat("       -d        : debug hashedDrops(). TRUE or FALSE\n")
    cat("       -o        : outdir location to write results\n")
}

ARG = commandArgs(trailingOnly = TRUE)

if(length(ARG) < 9) {
    usage("Potentially missing arguments")
}

## get arg variables
for (i in 1:length(ARG)) {
    if (ARG[i] == "-b") {
        hto_frs_id=ARG[i+1]
    } else if (ARG[i] == "-a") {
        arcseq_frs_id=ARG[i+1]
    } else if (ARG[i] == "-n") {
        ngs_id=ARG[i+1]
    } else if (ARG[i] == "-t") {
        test_ranks=ARG[i+1]
    } else if (ARG[i] == "-r") {
        rank=ARG[i+1]
    } else if (ARG[i] == "-p") {
        num_threads=ARG[i+1]
    } else if (ARG[i] == "-o") {
        outdir=ARG[i+1]
    } else if (ARG[i] == "-i") {
        n_iters=ARG[i+1]
    } else if (ARG[i] == "-k") {
        skip_sample=ARG[i+1]
    } else if (ARG[i] == "-d") {
        debug_hashedDrops=ARG[i+1]
    }
}

if(!is.defined(ngs_id))                       {ngs_id = NULL}
if(!is.defined(outdir))                       {outdir = NULL}
if(!is.defined(hto_frs_id))                   {hto_frs_id = NULL}
if(!is.defined(arcseq_frs_id))                {arcseq_frs_id = NULL}
if(!is.defined(skip_sample))                  {skip_sample = NULL}
if(!is.defined(test_ranks) | test_ranks == 0) {test_ranks = NULL}
if(!is.defined(debug_hashedDrops))            {debug_hashedDrops = FALSE}

demultiplex_hto_and_scRNA(num_threads=num_threads, ngs_id=ngs_id, outdir=outdir, test_ranks=test_ranks, rank=rank, hto_frs_id=hto_frs_id, arcseq_frs_id=arcseq_frs_id, n_iters=n_iters, debug_hashedDrops=debug_hashedDrops)
